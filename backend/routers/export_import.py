# ==============================================
# backend/routers/export_import.py
# ì—­í• : JSON ì „ì²´ ë‚´ë³´ë‚´ê¸°, ë§ˆí¬ë‹¤ìš´ ZIP ë‚´ë³´ë‚´ê¸°, JSON ê°€ì ¸ì˜¤ê¸°
# Pythonìœ¼ë¡œ ì¹˜ë©´: Flask Blueprint('export_import', ...)
# ==============================================

import io
import json
import shutil
import zipfile
from datetime import datetime
from pathlib import Path

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse

from backend.core import (
    VAULT_DIR,
    ImportBody,
    assert_inside_vault,
    load_index,
    save_index,
)

# Pythonìœ¼ë¡œ ì¹˜ë©´: blueprint = Blueprint('export_import', __name__, url_prefix='/api')
router = APIRouter(prefix="/api", tags=["export_import"])


# -----------------------------------------------
# ë‚´ë³´ë‚´ê¸°
# -----------------------------------------------

@router.get("/export/json")
def export_json():
    """
    ì „ì²´ vaultë¥¼ ë‹¨ì¼ JSON íŒŒì¼ë¡œ ë‚´ë ¤ë°›ê¸°
    Pythonìœ¼ë¡œ ì¹˜ë©´: return send_file(json_bytes, as_attachment=True)
    """
    index = load_index()
    pages_data = []

    # ëª¨ë“  í˜ì´ì§€ content.json ìˆ˜ì§‘ (folderMap ê¸°ë°˜)
    # Pythonìœ¼ë¡œ ì¹˜ë©´: for page_id in pageOrder: pages.append(load(folder))
    folder_map = index.get("folderMap", {})
    category_map = index.get("categoryMap", {})
    categories = {c["id"]: c["folderName"] for c in index.get("categories", [])}

    for page_id in index.get("pageOrder", []):
        folder_name = folder_map.get(page_id)
        if not folder_name:
            continue

        cat_id = category_map.get(page_id)
        cat_folder = categories.get(cat_id) if cat_id else None

        if cat_folder:
            content_path = VAULT_DIR / cat_folder / folder_name / "content.json"
        else:
            content_path = VAULT_DIR / folder_name / "content.json"

        if content_path.exists():
            pages_data.append(json.loads(content_path.read_text(encoding="utf-8")))

    export_obj = {
        "exportedAt": datetime.now().isoformat(),
        "version": "2.0",
        "index": index,
        "pages": pages_data,
    }

    json_bytes = json.dumps(export_obj, ensure_ascii=False, indent=2).encode("utf-8")
    filename = f"notion-clone-backup-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"

    return StreamingResponse(
        io.BytesIO(json_bytes),
        media_type="application/json",
        headers={"Content-Disposition": f'attachment; filename="{filename}"'},
    )


@router.get("/export/markdown")
def export_markdown():
    """
    ì „ì²´ vaultë¥¼ ë§ˆí¬ë‹¤ìš´ ZIPìœ¼ë¡œ ë‚´ë ¤ë°›ê¸°
    Pythonìœ¼ë¡œ ì¹˜ë©´: zipfile.write(md_content); return send_file(zip)
    """
    index = load_index()
    zip_buffer = io.BytesIO()

    def blocks_to_markdown(blocks: list) -> str:
        """ë¸”ë¡ ë°°ì—´ â†’ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë³€í™˜"""
        lines = []
        for block in blocks:
            btype = block.get("type", "paragraph")
            content = block.get("content", "")

            if btype == "heading1":
                lines.append(f"# {content}")
            elif btype == "heading2":
                lines.append(f"## {content}")
            elif btype == "heading3":
                lines.append(f"### {content}")
            elif btype == "bulletList":
                lines.append(f"- {content}")
            elif btype == "orderedList":
                lines.append(f"1. {content}")
            elif btype == "taskList":
                checked = "x" if block.get("checked") else " "
                lines.append(f"- [{checked}] {content}")
            elif btype == "quote":
                lines.append(f"> {content}")
            elif btype == "code":
                lines.append(f"```\n{content}\n```")
            elif btype == "divider":
                lines.append("---")
            elif btype == "kanban":
                lines.append("[ì¹¸ë°˜ ë³´ë“œ]")
            elif btype == "layout":
                # ë ˆì´ì•„ì›ƒ ë¸”ë¡: ìŠ¬ë¡¯ Aâ†’Bâ†’C ìˆœì„œë¡œ ì„ í˜•í™” (--- êµ¬ë¶„ì„  ì‚½ì…)
                # Pythonìœ¼ë¡œ ì¹˜ë©´: for slot in ['a','b','c']: lines += blocks_to_md(slot_blocks)
                try:
                    layout_data = json.loads(content) if isinstance(content, str) else {}
                    slot_parts = []
                    for slot_id in ["a", "b", "c"]:
                        slot_blocks = layout_data.get("slots", {}).get(slot_id, [])
                        if slot_blocks:
                            slot_md = blocks_to_markdown(slot_blocks).strip()
                            if slot_md:
                                slot_parts.append(slot_md)
                    if slot_parts:
                        lines.append("\n\n---\n\n".join(slot_parts))
                    else:
                        lines.append("[ë ˆì´ì•„ì›ƒ ë¸”ë¡]")
                except Exception:
                    lines.append("[ë ˆì´ì•„ì›ƒ ë¸”ë¡]")
            else:
                lines.append(content)
            lines.append("")  # ë¹ˆ ì¤„ êµ¬ë¶„
        return "\n".join(lines)

    folder_map = index.get("folderMap", {})
    category_map = index.get("categoryMap", {})
    categories = {c["id"]: c["folderName"] for c in index.get("categories", [])}

    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for page_id in index.get("pageOrder", []):
            folder_name = folder_map.get(page_id)
            if not folder_name:
                continue

            cat_id = category_map.get(page_id)
            cat_folder = categories.get(cat_id) if cat_id else None

            if cat_folder:
                content_path = VAULT_DIR / cat_folder / folder_name / "content.json"
                zip_path = f"{cat_folder}/{folder_name}.md"
            else:
                content_path = VAULT_DIR / folder_name / "content.json"
                zip_path = f"{folder_name}.md"

            if not content_path.exists():
                continue

            page_data = json.loads(content_path.read_text(encoding="utf-8"))
            title = page_data.get("title", "ì œëª© ì—†ìŒ")
            blocks = page_data.get("blocks", [])

            md_lines = [f"# {title}", ""]
            md_lines.append(blocks_to_markdown(blocks))
            md_content = "\n".join(md_lines)
            zf.writestr(zip_path, md_content.encode("utf-8"))

    zip_buffer.seek(0)
    filename = f"notion-clone-markdown-{datetime.now().strftime('%Y%m%d-%H%M%S')}.zip"

    return StreamingResponse(
        zip_buffer,
        media_type="application/zip",
        headers={"Content-Disposition": f'attachment; filename="{filename}"'},
    )


# -----------------------------------------------
# ê°€ì ¸ì˜¤ê¸°
# -----------------------------------------------

@router.post("/import")
def import_json(body: ImportBody):
    """
    JSON ë°±ì—…ì—ì„œ vault ë³µêµ¬
    Pythonìœ¼ë¡œ ì¹˜ë©´: shutil.rmtree(vault); restore(backup_data)

    ì£¼ì˜: ê¸°ì¡´ vaultë¥¼ ì™„ì „íˆ ë®ì–´ì”€
    """
    data = body.data
    new_index = data.get("index", {})
    pages_list = data.get("pages", [])

    # ê¸°ì¡´ vault ë°±ì—… (rollback ê°€ëŠ¥í•˜ë„ë¡)
    backup_dir = VAULT_DIR.parent / f"vault_bak_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    if VAULT_DIR.exists():
        shutil.copytree(str(VAULT_DIR), str(backup_dir))

    try:
        # vault ì´ˆê¸°í™” (ì´ë¯¸ì§€ ì œì™¸)
        for item in VAULT_DIR.iterdir():
            if item.name == "_index.json":
                continue
            if item.is_dir():
                shutil.rmtree(str(item))

        # index ì €ì¥
        save_index(new_index)

        # ê° í˜ì´ì§€ content.json ë³µêµ¬ (folderMap ê¸°ë°˜)
        folder_map = new_index.get("folderMap", {})
        category_map = new_index.get("categoryMap", {})
        categories = {c["id"]: c.get("folderName", "") for c in new_index.get("categories", [])}

        for page_data in pages_list:
            page_id = page_data.get("id", "")
            folder_name = folder_map.get(page_id, page_data.get("folder", ""))
            if not folder_name:
                continue

            cat_id = category_map.get(page_id)
            cat_folder = categories.get(cat_id) if cat_id else None

            if cat_folder:
                target_dir = VAULT_DIR / cat_folder / folder_name
            else:
                target_dir = VAULT_DIR / folder_name

            # ğŸ”’ vault íƒˆì¶œ ë°©ì§€
            assert_inside_vault(target_dir)

            target_dir.mkdir(parents=True, exist_ok=True)
            (target_dir / "content.json").write_text(
                json.dumps(page_data, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )

        # ì„ì‹œ ë°±ì—… ì‚­ì œ (ì„±ê³µ ì‹œ)
        if backup_dir.exists():
            shutil.rmtree(str(backup_dir))

        return {"ok": True, "imported": len(pages_list)}

    except HTTPException:
        # ë³´ì•ˆ ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ (vault ë³µêµ¬ í›„)
        if backup_dir.exists():
            shutil.rmtree(str(VAULT_DIR))
            shutil.copytree(str(backup_dir), str(VAULT_DIR))
            shutil.rmtree(str(backup_dir))
        raise

    except Exception as exc:
        # ì‹¤íŒ¨ ì‹œ ë°±ì—…ì—ì„œ ë¡¤ë°±
        if backup_dir.exists():
            shutil.rmtree(str(VAULT_DIR))
            shutil.copytree(str(backup_dir), str(VAULT_DIR))
            shutil.rmtree(str(backup_dir))
        raise HTTPException(status_code=500, detail=str(exc)) from exc
